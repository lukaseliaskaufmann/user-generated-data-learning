{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2025*\n",
    "# Exercise 2: Collaborative Filtering + Implicit Feedback\n",
    "\n",
    "In this exercise we create our first proper recommender: Item-based K-Nearest Neighbours (ItemKNN) on implicit feedback from the family of Collaborative Filtering algorithms. Please refer to the slides and the recording of the relevant UE session published on Moodle if you have any problems. Feel free to ask questions in the Discussions forum.\n",
    "\n",
    "The assignment submission deadline is (see Moodle).\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\\\n",
    "LUD25_ex02_k<font color='red'>\\<Matr. 12312127\\></font>_<font color='red'>\\<Kaufmann-Lukas></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD25_ex02_k000007_Bond-James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise you are required to write three functions each calling the previous. Every function will be graded separately. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency (a single run of any function should not take more than 2 minutes).\n",
    "\n",
    "Please only use libraries already imported in the notebook. **Feel free to experiment with the notebook, but clean it up before submitting.**\n",
    "    \n",
    "The asserts present are meant for the LFM-tiny dataset from the previous exercise.\n",
    "\n",
    "## Item-Based Collaborative Filtering\n",
    "The idea of Item-Based Collaborative Filtering is to estimate if a user **u** is going to like item **i** through checking how similar this item is to the items already consumed (and rated) by the user. One way to calculate the estimation is a sum of ratings given by **u** to the consumed items weighted with their respective similarities to the item **i**. Please note, that from all items consumed by the user we only consider top **n** items most similar to item **i**.\n",
    "\n",
    "In case of implicit feedback (which we deal with in this exercise), all \"ratings\" are either 0 or 1. Therefore, we combine our score from the similarities themselves. In this exercise we take the **average** of similarities to top **n** (or less if not enough neighbors were found) most similar to **i** items. Also note that we don't have to account for biases and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Matrix\n",
    "\n",
    "In this exercise we work with the same format of interaction matrices as in the Exercise 1 (default settings) and the same data (LFM-tiny). Find a way to use the matrix in this notebook (e.g. copy your implementation of inter_matr_binary here and create the matrix anew)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: pd.DataFrame,\n",
    "                        items: pd.DataFrame,\n",
    "                        interactions: pd.DataFrame,\n",
    "                        dataset_name: str,\n",
    "                        threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    users - pandas Dataframe, use it as loaded from the dataset;\n",
    "    items - pandas Dataframe, use it as loaded from the dataset;\n",
    "    interactions - pandas Dataframe, use it as loaded from the dataset;\n",
    "    dataset_name - string out of [\"lfm-ismir\", \"ml-1m\"], name of the dataset, used in case there are differences in the column names of the data frames;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "\n",
    "    returns - 2D np.ndarray, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "    if dataset_name == \"lfm-tiny\":\n",
    "        user_col = \"user_id\"\n",
    "        item_col = \"item_id\"\n",
    "        interaction_col = \"listening_events\"\n",
    "    elif dataset_name == \"ml-1m\":\n",
    "        user_col = \"user_id\"\n",
    "        item_col = \"item_id\"  \n",
    "        interaction_col = \"rating\"\n",
    "    else:\n",
    "        raise ValueError(\"Dataset name must be 'lfm-tiny' or 'ml-1m'\")\n",
    "    \n",
    "    # User- und Item-Mappings erstellen\n",
    "    user_ids = users[user_col].unique()\n",
    "    item_ids = items[item_col].unique()\n",
    "    \n",
    "    user_map = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    item_map = {iid: i for i, iid in enumerate(item_ids)}\n",
    "    \n",
    "    # Interaktionsmatrix initialisieren\n",
    "    interaction_matrix = np.zeros((len(user_ids), len(item_ids)), dtype=np.int8)\n",
    "    \n",
    "    # Interaktionsdaten filtern (nur relevante Spalten)\n",
    "    interactions_filtered = interactions[[user_col, item_col, interaction_col]]\n",
    "    \n",
    "    # Nur Interaktionen über dem Schwellenwert behalten\n",
    "    interactions_filtered = interactions_filtered[interactions_filtered[interaction_col] >= threshold]\n",
    "    \n",
    "    # Eintragen der Interaktionen in die Matrix\n",
    "    for _, row in interactions_filtered.iterrows():\n",
    "        user_idx = user_map.get(row[user_col])\n",
    "        item_idx = item_map.get(row[item_col])\n",
    "        if user_idx is not None and item_idx is not None:\n",
    "            interaction_matrix[user_idx, item_idx] = 1  # Binäre Interaktion\n",
    "    \n",
    "    return interaction_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data for both datasets, keep it as specified in the csv files\n",
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "users = read(\"lfm-tiny\", 'user')\n",
    "items = read(\"lfm-tiny\", 'item')\n",
    "interactions = read(\"lfm-tiny\", 'inter')\n",
    "\n",
    "\n",
    "\n",
    "_interaction_matrix_test = inter_matr_implicit(users, items, interactions, \"lfm-tiny\", 1)\n",
    "_interaction_matrix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/3</font>: Get item similarities (3 points)\n",
    "This is a helper function to be later used for user-item score estimation.\n",
    "The function should take three arguments: a similarity measure (Jaccard distance in our case, see below), a binary interaction_matrix-like numpy array **inter** and a plane binary vector corresponding to an item **target_vec**. You can expect that the length of the vector corresponds to the number of users in the matrix **inter** (first parameter).\n",
    "\n",
    "*the vector can be just a slice of the interaction matrix, see asserts*\n",
    "\n",
    "Expected output: array of similarities between every item in **inter** and the vector **target_vec**. The similarities need to be placed in the order the items appear in the matrix **inter**.\n",
    "\n",
    "Example: **inter** is a 7 by 3 matrix, containing information about 3 items and 7 users (can be expressed through item vectors as [it1; it2; it3]). **target_vec** is a vector of length 7 (assuming it tells us about interactions between the item and the same 7 users). The expected output is an array of length 3:\\\n",
    "[*sim*(it1, target_vec), *sim*(it2, target_vec), *sim*(it3, target_vec)]\n",
    "\n",
    "**Similarity:** use jaccard score as the similarity measure. Please implement it yourself, don't use any external libraries;\\\n",
    "If $a$ and $b$ are two items, let's define $U(a)$ as the set of users, interacted with the item $a$ (same for $b$). $|U(a)|$ corresponds to the number of users interacted with the item $a$ (cardinality of the set). Then Jaccard similarity score between the two items is defined as:\\\n",
    "\\\n",
    "$JaccardScore(a,b) = \\frac{|U(a) \\wedge U(b)|}{|U(a) \\vee U(b)|}$\n",
    "\n",
    "In words: Jaccard Score is the number of users interacted with both items divided by the number of users interacted with at least one of them.\n",
    "\n",
    "Use the cell below to define the similarity as a helper function, please don't change the parameters, name or output format.\n",
    "\n",
    "<b>Tip:</b> The item vectors are on the axis=1 in the matrix.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_score(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    a, b - 1D np.ndarray, vectors of the same length corresponding to the two items;\n",
    "\n",
    "    returns - float, jaccard similarity score for a and b;\n",
    "    \"\"\"\n",
    "    set_a = {i for i, val in enumerate(a) if val == 1}\n",
    "    set_b = {i for i, val in enumerate(b) if val == 1}\n",
    "    \n",
    "    intersection = len(set_a & set_b)  # Common users interacted with both items\n",
    "    union = len(set_a | set_b)  # Users who interacted with at least one item\n",
    "\n",
    "    return intersection / union if union != 0 else 0.0  # Avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sim_scores(similarity_measure: Callable[[np.ndarray, np.ndarray], float],\n",
    "                         inter: np.ndarray,\n",
    "                         target_vec: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    similarity_measure - Callable, function that measures similarity, it gets called using your jaccard_score function from above - as always do not directly call your function, but use the passed parameter;\n",
    "    inter - np.ndarray, interaction matrix - calculate similarity between each item and the target item (see below);\n",
    "    target_vec - np.ndarray, target item vector;\n",
    "    \n",
    "    returns - np.ndarray, similarities between every item from <inter> and <target_vec> in the respective order;\n",
    "    \"\"\"\n",
    "    return [similarity_measure(item, target_vec) for item in inter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please call the function for the <b>whole</b> _interaction_matrix_test and the vector of the item with the <b>id 0</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.02083333 0.01030928 0.03529412 0.01449275 0.05555556\n",
      " 0.04347826 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04545455 0.\n",
      " 0.         0.04545455 0.11764706 0.05882353 0.05882353 0.02150538\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01898734 0.         0.         0.04545455 0.\n",
      " 0.         0.         0.         0.01265823 0.         0.\n",
      " 0.         0.         0.0625     0.         0.         0.05\n",
      " 0.05555556 0.05555556 0.08695652 0.05769231 0.0625     0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07142857 0.         0.         0.\n",
      " 0.0625     0.01315789 0.0625     0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.04       0.         0.         0.         0.         0.03174603\n",
      " 0.         0.         0.01234568 0.         0.02040816 0.\n",
      " 0.         0.04545455 0.         0.00694444 0.02380952 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.02816901 0.         0.         0.02040816 0.02631579 0.\n",
      " 0.         0.         0.         0.03703704 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01960784\n",
      " 0.         0.         0.03030303 0.01886792 0.         0.\n",
      " 0.         0.         0.         0.01612903 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.00740741 0.         0.         0.         0.\n",
      " 0.02325581 0.04166667 0.04761905 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01030928\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03225806 0.         0.         0.         0.02380952 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01204819 0.         0.         0.\n",
      " 0.         0.         0.         0.0212766  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.02702703\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01639344 0.02857143 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.025      0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04761905 0.\n",
      " 0.04166667 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05882353 0.         0.         0.04347826 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.03571429 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.04347826 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.05882353\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# here we pass your jaccard_score function as \"similarity_measure\" parameter\n",
    "_interaction_matrix_test = inter_matr_implicit(users, items, interactions, \"lfm-tiny\", 1)\n",
    "\n",
    "target_vec = _interaction_matrix_test[:, 0] \n",
    "\n",
    "item_sims = np.array(calculate_sim_scores(jaccard_score, _interaction_matrix_test.T, target_vec))\n",
    "\n",
    "print(item_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert item_sims is not None, \"item_sims should not be None.\"\n",
    "assert type(item_sims) == np.ndarray, \"types are not correct.\"\n",
    "assert len(item_sims) == 412, \"length is not correct.\"\n",
    "assert item_sims[0] == 1, \"Item at the index 0 should have sim of 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/3</font>: Estimate user-item score (3 points)\n",
    "\n",
    "Write a function that takes a full interaction matrix as an input, as well as user id, item id and *n* -- algorithm's hyperparameter, number of neighbors to be considered while calculating the score.\n",
    "\n",
    "The expected output is a single number between 0 and 1 - the predicted score.\n",
    "\n",
    "Refer to the slides and the recording. Follow the algorithm:\n",
    "* take items consumed by the user\n",
    "* calculate the similarities between them and the target item (**exclude the target user from consideration** when calculating the similarities!)\n",
    "* return **average** of top **n** with the highest similarity scores\n",
    "\n",
    "<b>Tip:</b> Copy the interaction matrix before using it.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_item_score(sim_scores_calculator: Callable[[np.ndarray, np.ndarray], np.ndarray],\n",
    "                        inter: np.ndarray,\n",
    "                        target_user: int,\n",
    "                        target_item: int,\n",
    "                        n: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Estimate the user-item score based on item similarities.\n",
    "    \n",
    "    Parameters:\n",
    "    sim_scores_calculator - Function that calculates similarity scores.\n",
    "    inter - np.ndarray, interaction matrix.\n",
    "    target_user - int, target user id.\n",
    "    target_item - int, target item id.\n",
    "    n - int, number of closest neighbors to consider.\n",
    "    \n",
    "    Returns:\n",
    "    float, mean similarity score of top n most similar items.\n",
    "    \"\"\"\n",
    "    # Copy interaction matrix to avoid modification\n",
    "    inter_copy = inter.copy()\n",
    "    \n",
    "    # Get items the user has interacted with\n",
    "    user_interactions = np.where(inter_copy[target_user] > 0)[0]\n",
    "    \n",
    "    # If no interactions, return 0\n",
    "    if len(user_interactions) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Compute similarity scores between interacted items and the target item\n",
    "    item_similarities = sim_scores_calculator(inter_copy[:, user_interactions], inter_copy[:, target_item])\n",
    "    \n",
    "    # Sort similarities in descending order\n",
    "    top_n_similarities = np.sort(item_similarities)[-n:]\n",
    "    \n",
    "    # Compute mean of top n similarities\n",
    "    item_similarities_mean = np.mean(top_n_similarities) if len(top_n_similarities) > 0 else 0.0\n",
    "    \n",
    "    return item_similarities_mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, call your function for <b>user 0</b> and <b>item 0</b> and <b> n = 10</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011627906976744186\n"
     ]
    }
   ],
   "source": [
    "# you need to pass a \"sim_scores_calculator\" function into the \"get_user_item_score\" function,\n",
    "# but \"calculate_sim_scores\" also takes a similarity measure function as parameter.\n",
    "# The similarity measure is not necessarily present inside the \"get_user_item_score\" function\n",
    "# Ideally you want to provide the similarity measure together with the \"calculate_sim_scores\" function\n",
    "\n",
    "# The following line of code is one possible way to \"bind\" parameters to a function: you can now use the \"sim_score_calc\" function as parameter,\n",
    "# which will always use your \"jaccard_score\" function as first parameter for \"calculate_sim_scores\" and passes through the other parameters\n",
    "# This procedure is a way to keep your functions generic, you can now simply change your similarity measure via the\n",
    "# function calls without needing to change the function bodies themselves\n",
    "#\n",
    "# Another advantage for you is that when we test your solution, we are going to pass our own implementations into your functions\n",
    "# That means if you made a mistake in Task 1, you will still be able to get full points for consequent tasks if you did everything else correctly\n",
    "# So make sure that your functions work independently of your other implemented functions by using the code we provide in this cell\n",
    "\n",
    "def sim_score_calc(inter, target_vec):\n",
    "    return calculate_sim_scores(jaccard_score, inter, target_vec)\n",
    "\n",
    "# Generating the interaction matrix\n",
    "_interaction_matrix_test = inter_matr_implicit(users, items, interactions, \"lfm-tiny\", 1)\n",
    "\n",
    "# Get the interaction vector for the target item\n",
    "target_vec = _interaction_matrix_test[:, target_item_id]  \n",
    "\n",
    "# Calculate item similarity\n",
    "item_sim = get_user_item_score(sim_score_calc, _interaction_matrix_test, target_user_id, target_item_id, n_neighbors)\n",
    "\n",
    "print(item_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert item_sim is not None, \"item sim should have a value.\"\n",
    "assert item_sim <= 1 and item_sim >= 0, \"value of item sim is not valid.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 3/3</font>: Recommender (4 points)\n",
    "\n",
    "Implement the recommender function for the scoring algorithm you implemented above.\n",
    "The function takes user_item_scorer (wrapper function already defined below), a full interaction matrix, user id, top_k, hyperparameter **n** as an input. It returns two arrays:\n",
    "\n",
    "* top_k recommendations for the given user obtained considering **n** neighbors for score prediction\n",
    "* the corresponding user-item similarity scores\n",
    "\n",
    "Make sure you recommend items the user **hasn't seen** before! Try optimizing your implementation so that the runs take seconds rather than minutes.\n",
    "\n",
    "Please don't change the \"interface\" of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recTopK(user_item_scorer: Callable[[Callable, np.ndarray, int, int], float],\n",
    "            inter_matr: np.ndarray,\n",
    "            user: int,\n",
    "            top_k: int,\n",
    "            n: int) -> (np.ndarray, np.ndarray):\n",
    "    '''\n",
    "    user_item_scorer - Callable, wrapper function that calculates user-item score, using get_user_item_score function\n",
    "                                 from above, already defined in the next cell;\n",
    "    inter_matr - np.ndarray, interaction matrix;\n",
    "    user - int,  user_id;\n",
    "    top_k - int, expected length of the resulting list;\n",
    "    n - int, number of neighbors to consider;\n",
    "    \n",
    "    returns - 1D np.ndarray, of recommendations (sorted in the order of descending scores) & 1D np.ndarray, of corresponding scores;\n",
    "    '''\n",
    "    print(\"debug1\")\n",
    "    top_rec = None\n",
    "    scores = None\n",
    "\n",
    "    num_items = inter_matr.shape[1]  # Total number of items\n",
    "\n",
    "    # Get items the user has already interacted with\n",
    "    seen_items = np.where(inter_matr[user] > 0)[0]\n",
    "\n",
    "    # Create a mask to exclude seen items\n",
    "    all_items = np.arange(num_items)\n",
    "    unseen_items = np.setdiff1d(all_items, seen_items)\n",
    "\n",
    "    print(\"debug2\")\n",
    "    \n",
    "    # Compute scores for unseen items\n",
    "    scores = np.array([user_item_scorer(inter_matr, user, item, n) for item in unseen_items])\n",
    "\n",
    "    # Get indices of the top_k highest scores\n",
    "    top_k_indices = np.argsort(scores)[-top_k:][::-1]  # Sorting in descending order\n",
    "\n",
    "    # Retrieve the top_k recommendations and their corresponding scores\n",
    "    top_rec = unseen_items[top_k_indices]\n",
    "    top_scores = scores[top_k_indices]\n",
    "    \n",
    "    return np.array(top_rec), np.array(top_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets use these scoring functions and get the <b>top 10</b> recommendations for <b>user 0</b> with <b>n = 15</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug1\n",
      "debug2\n"
     ]
    }
   ],
   "source": [
    "# see Task 2 for an explanation of the following function definition\n",
    "\n",
    "top_k = 10\n",
    "n = 15\n",
    "user_id = 0  # Given user ID\n",
    "\n",
    "def user_item_scorer(inter, target_user, target_item, n):\n",
    "    return get_user_item_score(sim_score_calc, inter, target_user, target_item, n)\n",
    "\n",
    "# Generate recommendations\n",
    "rec_item_cf, scores_item_cf = recTopK(user_item_scorer, _interaction_matrix_test, target_user_id, top_k, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations with Item CF:  [22 21 50 49 20 18 25 19 16 37]\n",
      "With Scores:  [0.16666667 0.16666667 0.14828283 0.14828283 0.14285714 0.11111111\n",
      " 0.1        0.09090909 0.09090909 0.07939394]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendations with Item CF: \", rec_item_cf)\n",
    "print(\"With Scores: \", scores_item_cf)\n",
    "print(\"-\" * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rec_item_cf is not None, \"Recommendations should not be None.\"\n",
    "assert type(rec_item_cf) == np.ndarray, \"Types should be np.ndarray.\"\n",
    "assert len(rec_item_cf) == 10, \"10 recommendations should be returned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert scores_item_cf is not None, \"Scores should not be None.\"\n",
    "assert type(scores_item_cf) == np.ndarray, \"Types should be np.ndarray.\"\n",
    "assert len(scores_item_cf) == 10, \"10 recommendations should be returned.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
