{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2025*\n",
    "# Exercise 1: RecSys Basics II\n",
    "In this exercise we familiarize ourselves with recommender systems, a kind of data they use and implement a simple base-line recommendation algorithm.\n",
    "\n",
    "The assignment submission deadline is 11.03.2025 12:00.\n",
    "Please, don't forget to rename your Jupyter Notebook according to the convention:<br>\n",
    "\n",
    "LUD25_ex01_**k**<font color='red'>12312127</font>_<font color='red'>Kaufmann-Lukas</font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD25_ex01_**k**0000007_Bond-James.ipynb\n",
    "\n",
    "## Introduction\n",
    "* What are recommender systems?\n",
    "* Where do we encounter them?\n",
    "* What part does User-generated Data play in RecSys?\n",
    "\n",
    "## Recommendation Scenario\n",
    "Imagine a platform where users consume items: buy goods (Amazon), listen to music tracks (Deezer, Spotify), watch movies (Netflix) or videos (YouTube).\n",
    "\n",
    "At some point a user may face a choice: \"what item should I have a look at next?\" Can be that they don't know what exactly they need and are unable to formulate a query. Of course with catalogs of millions of items they have little chance finding something useful by browsing through all of them.\n",
    "\n",
    "In such situations Recommender Systems are expected to make the decision easier for the user by shrinking the scope to a handful of individually selected options, for example top 10 recommended songs.\n",
    "\n",
    "Information the recommendation can be based on:\n",
    "* Items already consumed by the user\n",
    "* Items consumed by other users\n",
    "* User relations\n",
    "* Item meta-data & content\n",
    "* ...\n",
    "\n",
    "User-Item interactions is one of the most widely used signals in recommendation. Initially it can be available in a form of system logs (see table below). There is a multitude of ways a user can interact with an item: consume (buy, watch, listen), note (like, save to favorites), share and others. In this exercise we only deal with item consumption.\n",
    "\n",
    "#### Example: Raw User-Item Interactions Data\n",
    "| Meaningless but Unique<br>Event Id | User Id | Item Id | Event Type | Date |\n",
    "| ---         |---  |--- |---   |   ---    |\n",
    "| 002Ax4gf... | 12  | 2  | 6000 | 13.04.08 |\n",
    "| 9f2D4jKx... | 908 | 2  | 6000 | 01.02.09 |\n",
    "| 3g6lP89qs.. | 12  | 13 | 4800 | 11.10.10 |\n",
    "| ...         | ... |... | ...  | ...      |\n",
    "\n",
    "## Datasets\n",
    "Throughout the whole exercise track we will be mostly working on music & movie recommendation tasks. Note that all methods we consider are applicable to other domains!\n",
    "\n",
    "[LFM-2b](http://www.cp.jku.at/datasets/LFM-2b/) is a large dataset of over two billion listening events, spanning across ~15 years, crawled from LastFM platform. It is supported with user demographics information and music track meta-data. In this exercise we take a look at a small sample of the aggregated LFM-2B (lfm-tiny) as well as MovieLens-1M dataset (ml-1m). Each of them consists of three files, in case of lfm-tiny it is:\n",
    "\n",
    "* 'lfm-tiny.inter' - data about user-track interactions;\n",
    "* 'lfm-tiny.item' - track-related information;\n",
    "* 'lfm-tiny.user' - user-related information;\n",
    "    \n",
    "And for ml-1m respectively:\n",
    "    \n",
    "* 'ml-1m.inter' - data about user-movie ratings;\n",
    "* 'ml-1m.item' - movie-related information;\n",
    "* 'ml-1m.user' - user-related information;\n",
    "\n",
    "### Important note:\n",
    "**'lfm-tiny.inter'** contains cumulative number of listening events per pair User-Track over the whole period;\n",
    "    \n",
    "**'ml-1m.inter'** contains **ratings** per pair User-Track on a scale from 1 to 5;\n",
    "\n",
    "**The interpretation of the interaction feedback (listening events or ratings) is usually up to the designer of a recommender system. In this course we treat any feedback as IMPLICIT FEEDBACK**.\n",
    "\n",
    "## Implicit feedback\n",
    "The MovieLens dataset provides us with ratings users give to movies, this allows us to judge if a user (dis)likes one movie more than the other.\n",
    "    \n",
    "However, we do not always have explicit information about whether a user likes or dislikes a certain item (and to which extent). In case of LFM-2B we only know how many times a user have interacted with a certain item. The fact of a single interaction with a track does not mean that the user enjoyed it, so how many interactions do we need to be sure?\n",
    "    \n",
    "Following the concept of **Implicit Feedback** we binarise our interaction data: to every pair **User** and **Item** we assign 1 - user sufficiently (enough times or gave a sufficiently high rating) interacted with the item **or** 0 - user did not interact with the item / did not enjoy it / unknown.\n",
    "    \n",
    "Very roughly speaking recommendation with implicit feedback is a binary classification problem: prediction of whether the user is going to interact with an item or not.\n",
    "\n",
    "## <font color='red'>TASKS</font>:\n",
    "\n",
    "Implement functions specified below. Please, don't change the signatures (names, parameters) and follow the specifications closely. Your implementation should not require any additional imports, apart from those already in the notebook.\n",
    "\n",
    "For testing purposes make sure the two dataset folders are placed in the same folder next to the .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1/3: Interaction Matrix (4 points)\n",
    "Interaction matrix is a common data structure used in some (not all) recommender algorithms. It is a matrix with dimensions: [number of users] times [number of items] known to the system. Every element in the matrix shows whether the given User ever interacted with the given Item. It can be done in a binary manner, as a probability or as a rating given by the User to the Item.\n",
    "\n",
    "**Write a function** that is able to create an interaction matrix from both ml-1m and lfm-tiny datasets. It receives three dataframes, dataset name and an int threshold value as input and returns a 2-dimensional numpy array with the corresponding interaction matrix, where **0** means the user didn't interact with the track on purpose or didn't like it (played the track \\< [threshold] times, or gave a rating \\< [threshold] in the case of ml-1m), **1** means the user listened to the track more than or equal to [threshold] times (or gave a rating that is higher or equal to [threshold] in the case of ml-1m).\n",
    "\n",
    "The first dimension of the matrix should correspond to users, second - to items.\n",
    "\n",
    "**Important note:** we introduce the threshold as a way to filter out interactions that are not necessarily meaningful (e.g. accidental playbacks or movies a user disliked).\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_matr_implicit(users: pd.DataFrame,\n",
    "                        items: pd.DataFrame,\n",
    "                        interactions: pd.DataFrame,\n",
    "                        dataset_name: str,\n",
    "                        threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    users - pandas Dataframe, use it as loaded from the dataset;\n",
    "    items - pandas Dataframe, use it as loaded from the dataset;\n",
    "    interactions - pandas Dataframe, use it as loaded from the dataset;\n",
    "    dataset_name - string out of [\"lfm-tiny\", \"ml-1m\"], name of the dataset, used in case there are differences in the column names of the data frames;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "\n",
    "    returns - 2D np.ndarray, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "\n",
    "    if dataset_name == \"lfm-tiny\":\n",
    "        user_col = \"user_id\"\n",
    "        item_col = \"item_id\"\n",
    "        interaction_col = \"listening_events\"\n",
    "    elif dataset_name == \"ml-1m\":\n",
    "        user_col = \"user_id\"\n",
    "        item_col = \"item_id\"  \n",
    "        interaction_col = \"rating\"\n",
    "    else:\n",
    "        raise ValueError(\"Dataset name must be 'lfm-tiny' or 'ml-1m'\")\n",
    "    \n",
    "    # User- und Item-Mappings erstellen\n",
    "    user_ids = users[user_col].unique()\n",
    "    item_ids = items[item_col].unique()\n",
    "    \n",
    "    user_map = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    item_map = {iid: i for i, iid in enumerate(item_ids)}\n",
    "    \n",
    "    # Interaktionsmatrix initialisieren\n",
    "    interaction_matrix = np.zeros((len(user_ids), len(item_ids)), dtype=np.int8)\n",
    "    \n",
    "    # Interaktionsdaten filtern (nur relevante Spalten)\n",
    "    interactions_filtered = interactions[[user_col, item_col, interaction_col]]\n",
    "    \n",
    "    # Nur Interaktionen über dem Schwellenwert behalten\n",
    "    interactions_filtered = interactions_filtered[interactions_filtered[interaction_col] >= threshold]\n",
    "    \n",
    "    # Eintragen der Interaktionen in die Matrix\n",
    "    for _, row in interactions_filtered.iterrows():\n",
    "        user_idx = user_map.get(row[user_col])\n",
    "        item_idx = item_map.get(row[item_col])\n",
    "        if user_idx is not None and item_idx is not None:\n",
    "            interaction_matrix[user_idx, item_idx] = 1  # Binäre Interaktion\n",
    "    \n",
    "    return interaction_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the data for both datasets, keep it as specified in the csv files\n",
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "users_lfm = read(\"lfm-tiny\", 'user')\n",
    "items_lfm = read(\"lfm-tiny\", 'item')\n",
    "interactions_lfm = read(\"lfm-tiny\", 'inter')\n",
    "\n",
    "users_ml = read(\"ml-1m\", 'user')\n",
    "items_ml = read(\"ml-1m\", 'item')\n",
    "interactions_ml = read(\"ml-1m\", 'inter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your solution:\n",
    "Run your function on the data discussed above and make sure that the result is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates interaction matrix for LFM dataset, choose the correct threshold for this dataset\n",
    "_interaction_matrix_test_lfm = inter_matr_implicit(users_lfm, items_lfm, interactions_lfm, \"lfm-tiny\", threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert _interaction_matrix_test_lfm is not None, \"Interaction Matrix should not be None!\"\n",
    "assert type(_interaction_matrix_test_lfm) == np.ndarray, \"Interaction Matrix should be a numpy array!\"\n",
    "assert _interaction_matrix_test_lfm.shape == (1194, 412), \"Shape of Interaction Matrix is wrong!\"\n",
    "assert np.array_equal(np.unique(_interaction_matrix_test_lfm),\n",
    "                      [0, 1]), \"Interaction Matrix should only contain 0 and 1!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creates interaction matrix for Movielens dataset, choose the correct threshold for this dataset\n",
    "_interaction_matrix_test_ml = inter_matr_implicit(users_ml, items_ml, interactions_ml, \"ml-1m\", threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert _interaction_matrix_test_ml is not None, \"Interaction Matrix should not be None!\"\n",
    "assert type(_interaction_matrix_test_ml) == np.ndarray, \"Interaction Matrix should be a numpy array!\"\n",
    "assert _interaction_matrix_test_ml.shape == (6040, 3883), \"Shape of Interaction Matrix is wrong!\"\n",
    "assert np.array_equal(np.unique(_interaction_matrix_test_ml), [0, 1]), \"Interaction Matrix should only contain 0 and 1!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2/3: POP Recommender (4 points)\n",
    "One of the most straightforward approaches to recommendation -- recommending the most popular items to every user. We call such recommender POP. It is a useful (and quite strong) baseline for creating more sophisticated systems and can be a default recommender, when there is no data available to build the recommendation upon (for example if the user has just joined the platform and haven't interacted with anything yet). Through the whole exercise track we only recommend items **not seen** by the user before (repeated consumption is out of our scope).\n",
    "\n",
    "**Write a function** that recommends [K] most popular items to a given user, **making sure that the user hasn't seen any of the recommended items before.**\n",
    "\n",
    "The function should take three arguments: np.array of arbitrary dimensions (supporting any number of users and items) in the format from task 1 (interaction matrix), user ID (int) and K (int > 0).\n",
    "Expected return: a list or a 1D array with [K] IDs of most popular items (sorted in the order of descending popularity) **not seen** by the user.\n",
    "\n",
    "Insert your solution into the signature below. Please, don't change the name or the argument set, even if they are not beautiful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recTopKPop(inter_matr: np.ndarray,\n",
    "               user: int,\n",
    "               top_k: int) -> np.array:\n",
    "    '''\n",
    "    inter_matr - np.ndarray, from the task 1;\n",
    "    user - int, user_id;\n",
    "    top_k - int, expected length of the resulting list;\n",
    "\n",
    "    returns - list/array, of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "\n",
    "    top_pop = None\n",
    "\n",
    "    # Compute item popularity by summing interactions across all users\n",
    "    item_popularity = np.sum(inter_matr, axis=0)\n",
    "    \n",
    "    # Get indices of items sorted by popularity in descending order\n",
    "    sorted_items = np.argsort(item_popularity)[::-1]\n",
    "    \n",
    "    # Get items the user has already interacted with\n",
    "    seen_items = set(np.where(inter_matr[user] > 0)[0])\n",
    "    \n",
    "    # Filter out seen items and select the top K popular ones\n",
    "    top_pop = [item for item in sorted_items if item not in seen_items][:top_k]\n",
    "    \n",
    "    return np.array(top_pop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your solution:\n",
    "Run your function on the interaction matrix prepared before, make sure the input/output is correctly formatted.<br>\n",
    "Get the <b>top 10</b> recommendations for <b>user 0</b>.\n",
    "What are the tracks recommended to them? Would you like such recommendation? Will <b>user 0</b> like it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR IMPLEMENTATION\n",
    "top_10 = recTopKPop(_interaction_matrix_test_lfm, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert type(top_10) == np.ndarray, \"Output should be an array.\"\n",
    "assert len(top_10) == 10, \"Length is not right.\"\n",
    "# these recommendations are correct for the lfm dataset, comment it out if you are using ml-1m\n",
    "assert np.array_equal(top_10, np.array([ 42,  43,  51,  96, 105, 151,  12, 104,  68, 150])), \"Wrong recommendations.\"\n",
    "# these recommendations are correct for the ml-1m dataset, comment it out if you are using lfm\n",
    "# assert np.array_equal(top_10, np.array([2789, 1178, 1192, 476, 585, 2502,  589, 1539, 1180, 108])), \"Wrong recommendations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3/3: POP Recommender Country (2 points)\n",
    "Use what you have learned in Task 2 and implement a new version of POP recommender that to each user recomends top_k unseen tracks, most popular among users from the same country as the user.\n",
    "\n",
    "The function needs to figure out the country of the target user (the one receiving recommendations), see what is popular in that country, and then recommend top items not seen by the user before.\n",
    "\n",
    "Please note the additional parameter **users**, Dataframe consisting of user data with a \"country\" column (think of the .user file in the dataset), use it well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def recTopKPopByCountry(inter_matr: np.ndarray,\n",
    "                        user: int,\n",
    "                        top_k: int,\n",
    "                        users: pd.DataFrame) -> np.ndarray:\n",
    "    '''\n",
    "    inter_matr - np.ndarray, from the task 1;\n",
    "    user - int, user_id;\n",
    "    top_k - int, expected length of the resulting list;\n",
    "    users: pandas DataFrame, consisting of user information for all users, requires a \"country\" column;\n",
    "\n",
    "    returns - list/array of top K popular items that the user has never seen\n",
    "              (sorted in the order of descending popularity);\n",
    "    '''\n",
    "    \n",
    "    # Create a mapping from user_id to matrix index\n",
    "    user_id_to_idx = {uid: idx for idx, uid in enumerate(users['user_id'].unique())}\n",
    "    \n",
    "    if user not in user_id_to_idx:\n",
    "        raise ValueError(\"User ID not found in users DataFrame\")\n",
    "    \n",
    "    user_idx = user_id_to_idx[user]\n",
    "    user_country = users.loc[users['user_id'] == user, 'country'].values[0]\n",
    "    \n",
    "    # Get users in the same country\n",
    "    country_users = users.loc[users['country'] == user_country, 'user_id'].values\n",
    "    country_user_indices = [user_id_to_idx[uid] for uid in country_users if uid in user_id_to_idx]\n",
    "    \n",
    "    # Compute item popularity within the country\n",
    "    country_interactions = inter_matr[country_user_indices, :]\n",
    "    item_popularity = np.sum(country_interactions, axis=0)\n",
    "    \n",
    "    # Sort items by popularity in descending order, breaking ties with item index\n",
    "    sorted_items = np.argsort(-item_popularity + np.arange(len(item_popularity)) * 1e-9)\n",
    "    \n",
    "    # Get items the user has already interacted with\n",
    "    seen_items = set(np.where(inter_matr[user_idx, :] > 0)[0])\n",
    "    \n",
    "    # Filter out seen items and select the top K popular ones\n",
    "    top_pop = [item for item in sorted_items if item not in seen_items][:top_k]\n",
    "    \n",
    "    return np.array(top_pop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check your solution:\n",
    "Run your function on the interaction matrix prepared before, make sure the input/output is correctly formatted.  Get the top 10 recommendations for user 0. What are the tracks recommended to them? Would you like such recommendation? Will user 0 like it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inter_matr_lfm = inter_matr_implicit(users_lfm, items_lfm, interactions_lfm, \"lfm-tiny\", threshold=1)\n",
    "# create a pandas Dataframe with user data that has at least a \"country column\"\n",
    "users = users_lfm\n",
    "top_10 = recTopKPopByCountry(inter_matr=inter_matr_lfm, user=0, top_k=10, users=users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Wrong recommendations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(top_10) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput should be an array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(top_10) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength is not right.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(top_10, np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m43\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m69\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m51\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m71\u001b[39m, \u001b[38;5;241m65\u001b[39m])), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong recommendations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Wrong recommendations."
     ]
    }
   ],
   "source": [
    "# Test your solution, assert will print a message if something is wrong, no message if everything is correct\n",
    "assert type(top_10) == np.ndarray, \"Output should be an array.\"\n",
    "assert len(top_10) == 10, \"Length is not right.\"\n",
    "assert np.array_equal(top_10, np.array([43, 42, 69, 30, 96, 33, 51, 11, 71, 65])), \"Wrong recommendations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final check\n",
    "* Your functions are going to be tested in isolation, make sure you don't use global variables;\n",
    "* Remove all the code you don't need, provide comments for the rest;\n",
    "* Check the execution time of your functions, if any of them takes more than one minute to execute on the given data, try optimizing it. Extremely inefficient solutions will get score penalties;\n",
    "* Don't forget to rename the notebook before submission;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave this cell the way it is, please."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-Hoa2]",
   "language": "python",
   "name": "conda-env-anaconda3-Hoa2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
